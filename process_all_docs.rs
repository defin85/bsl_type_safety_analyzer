use bsl_analyzer::docs_integration::BslSyntaxExtractor;
use std::time::Instant;

fn main() -> anyhow::Result<()> {
    // ĞĞ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .with_target(false)
        .init();
    
    let hbk_path = "C:/1CProject/1c-help-parser/data/rebuilt.shcntx_ru.zip";
    let output_dir = "output/docs_search";
    
    println!("=== BSL Syntax Documentation Full Export ===");
    println!("Source: {}", hbk_path);
    println!("Output: {}", output_dir);
    println!("Processing all HTML files from the archive...\n");
    
    // Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ extractor
    let mut extractor = BslSyntaxExtractor::new(hbk_path);
    
    // Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½ÑƒÑ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ
    let start_time = Instant::now();
    
    match extractor.extract_and_export_chunked(output_dir, None) {  // None = Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ²ÑĞµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
        Ok(()) => {
            let elapsed = start_time.elapsed();
            println!("\nâœ… Export completed successfully!");
            println!("â±ï¸  Total time: {:.2} seconds ({:.2} minutes)", 
                elapsed.as_secs_f64(), 
                elapsed.as_secs_f64() / 60.0
            );
            
            // ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
            show_export_statistics(output_dir)?;
        }
        Err(e) => {
            eprintln!("\nâŒ Export failed: {}", e);
            std::process::exit(1);
        }
    }
    
    Ok(())
}

fn show_export_statistics(output_dir: &str) -> anyhow::Result<()> {
    use std::fs;
    use std::path::Path;
    
    println!("\n=== Export Statistics ===");
    
    // Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ main_index.json Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸
    let main_index_path = Path::new(output_dir).join("main_index.json");
    if main_index_path.exists() {
        let content = fs::read_to_string(&main_index_path)?;
        let index: serde_json::Value = serde_json::from_str(&content)?;
        
        if let Some(stats) = index.get("statistics") {
            println!("ğŸ“Š Total items: {}", index["total_items"]);
            println!("ğŸ“ Total files: {}", stats["total_files"]);
            println!("ğŸ’¾ Total size: {:.2} MB", stats["total_size_mb"]);
            println!("ğŸ“ˆ Average items per file: {:.1}", stats["average_items_per_file"]);
            
            if let Some(coverage) = stats.get("coverage") {
                println!("\nğŸ“‹ Coverage:");
                println!("   - Processed: {} files", coverage["html_files_processed"]);
                println!("   - Total: {} files", coverage["html_files_total"]);
                println!("   - Coverage: {:.2}%", coverage["coverage_percent"]);
            }
            
            if let Some(processing) = stats.get("processing_info") {
                println!("\nâš™ï¸  Processing:");
                println!("   - Time: {:.2} seconds", processing["extraction_time_seconds"]);
                println!("   - Errors: {}", processing["errors_count"]);
                println!("   - Warnings: {}", processing["warnings_count"]);
            }
        }
        
        // ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºÑƒ Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸ÑĞ¼
        if let Some(categories) = index.get("categories").and_then(|c| c.as_object()) {
            println!("\nğŸ“‚ Categories:");
            let mut total_items = 0;
            for (category, info) in categories {
                let items = info["items_count"].as_u64().unwrap_or(0);
                let chunks = info["chunks_count"].as_u64().unwrap_or(0);
                println!("   - {}: {} items in {} files", category, items, chunks);
                total_items += items;
            }
            println!("   Total: {} items", total_items);
        }
    } else {
        println!("Main index not found!");
    }
    
    Ok(())
}